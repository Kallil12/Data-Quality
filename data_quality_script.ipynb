{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD3BsF2fK9d/ehgyi8cZKI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kEIg95GS8OWG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Functions\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GBTtRNw3IBwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_date_format(dataframe, date_columns):\n",
        "    def convert_date_format(date_str):\n",
        "        if isinstance(date_str, str):\n",
        "            try:\n",
        "                date_obj = datetime.datetime.strptime(date_str, '%m-%d-%Y')\n",
        "            except ValueError:\n",
        "                try:\n",
        "                    date_obj = datetime.datetime.strptime(date_str, '%m/%d/%Y')\n",
        "                except ValueError:\n",
        "                    return None\n",
        "            return date_obj.strftime('%m-%d-%Y') if date_obj else None\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    for date_column in date_columns:\n",
        "        dataframe[date_column] = dataframe[date_column].apply(lambda x: convert_date_format(x))\n"
      ],
      "metadata": {
        "id": "JpAhy5H88Uwo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_city_names(dataframe):\n",
        "    def process_city(city):\n",
        "        if isinstance(city, str):\n",
        "            city = city.rstrip(',')\n",
        "            city = re.sub(r'^B.*CANCOUR$', 'BECANCOUR', city)\n",
        "            city = re.sub(r'^Rivi.*-Rouge$', 'RIVIERE-ROUGE', city)\n",
        "        return city\n",
        "\n",
        "    dataframe['CITY_DEALER'] = dataframe['CITY_DEALER'].apply(process_city)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "7uvyYrwpWRSt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dealer_dataset(df_dealer):\n",
        "    # Remove duplicates\n",
        "    df_dealer.drop_duplicates(keep='first', inplace=True)\n",
        "\n",
        "    # Filter for 'US' and 'CA' in 'COUNTRY_CODE'\n",
        "    df_dealer = df_dealer[(df_dealer['COUNTRY_CODE'] == 'US') | (df_dealer['COUNTRY_CODE'] == 'CA')]\n",
        "\n",
        "    # Fill missing values in 'CITY_DEALER' with 'no city found'\n",
        "    df_dealer['CITY_DEALER'].fillna('no city found', inplace=True)\n",
        "\n",
        "    # Select columns of interest\n",
        "    df_dealer = df_dealer[['CUSTOMER_NUMBER', 'CITY_DEALER', 'COUNTRY_CODE', 'STATE_CODE']]\n",
        "\n",
        "    # Convert 'CUSTOMER_NUMBER' to integer\n",
        "    df_dealer['CUSTOMER_NUMBER'] = df_dealer['CUSTOMER_NUMBER'].astype(int)\n",
        "\n",
        "    # Define a region mapping dictionary\n",
        "    region_mapping = {\n",
        "        1: [\"AB\", \"BC\", \"MB\", \"NB\", \"NF\", \"NS\", \"NT\", \"NU\", \"ON\", \"PE\", \"QC\", \"SK\", \"YT\"],\n",
        "        2: [\"AL\", \"CT\", \"DE\", \"DC\", \"FL\", \"GA\", \"MA\", \"MD\", \"ME\", \"NC\", \"NH\", \"NJ\", \"NY\", \"PA\", \"PR\", \"RI\", \"SC\", \"VA\", \"VT\", \"WV\"],\n",
        "        3: [\"AR\", \"IA\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MI\", \"MN\", \"MO\", \"MS\", \"ND\", \"NE\", \"OH\", \"SD\", \"TN\", \"WI\"],\n",
        "        4: [\"AK\", \"AZ\", \"CA\", \"CO\", \"HI\", \"ID\", \"MT\", \"NM\", \"NV\", \"OK\", \"OR\", \"TX\", \"UT\", \"WA\", \"WY\"]\n",
        "    }\n",
        "\n",
        "    # Map 'REGION_CODE' based on 'STATE_CODE'\n",
        "    df_dealer['REGION_CODE'] = df_dealer['STATE_CODE'].apply(\n",
        "        lambda state: next((region for region, states in region_mapping.items() if state in states), 5)\n",
        "    )\n",
        "\n",
        "    return df_dealer"
      ],
      "metadata": {
        "id": "lEEIYfNCYoDs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_retail_dataset(df_retail):\n",
        "    # Remove 'x' characters from 'REG_DEALER_NUMBER'\n",
        "    df_retail['REG_DEALER_NUMBER'] = df_retail['REG_DEALER_NUMBER'].str.replace('x', '', regex=True)\n",
        "\n",
        "    # Set 'RETAIL' column to 1\n",
        "    df_retail['RETAIL'] = 1\n",
        "\n",
        "    # Convert 'REG_DEALER_NUMBER' to integer\n",
        "    df_retail['REG_DEALER_NUMBER'] = df_retail['REG_DEALER_NUMBER'].astype(int)\n",
        "\n",
        "    return df_retail"
      ],
      "metadata": {
        "id": "nkcIEiEAeEOP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_datasets(df_dealer, df_retail):\n",
        "    # Merge the DataFrames using an inner join\n",
        "    df_merged = pd.merge(df_retail, df_dealer, left_on='REG_DEALER_NUMBER', right_on='CUSTOMER_NUMBER', how='inner')\n",
        "\n",
        "    return df_merged"
      ],
      "metadata": {
        "id": "GnEj4Fdhg7vB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "End of function definitions\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QlCSAJx6IF97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Setting parameters\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "xbjuG5xCIJNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dealer_data_path = \"/content/sample_data/DEALER.csv\"\n",
        "retail_data_path = \"/content/sample_data/RETAIL_SALES.csv\""
      ],
      "metadata": {
        "id": "oXyZZmc0ITfV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dealer = pd.read_csv(dealer_data_path)\n",
        "df_retail = pd.read_csv(retail_data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdNwibwfIUWQ",
        "outputId": "f8cb87c6-5364-4da5-8abc-3980d726a8c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-8a4cc50ed4c7>:2: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_retail = pd.read_csv(retail_data_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dealer_date_columns = ['ATV_CREATION_DATE','PWC_CREATION_DATE',\n",
        "                       'SNOW_CREATION_DATE','THREE_W_CREATION_DATE',\n",
        "                       'SSV_CREATION_DATE']\n",
        "\n",
        "retail_date_columns = ['DELIVERY_DATE','FLOORING_END_DATE',\n",
        "                       'LAST_STORAGE_DATE','PAID_OFF_DATE',\n",
        "                       'REGISTRATION_DATE','DATE_OF_SALE',\n",
        "                       'INVOICE_DATE']"
      ],
      "metadata": {
        "id": "y4hwsZGoFHgO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "End of setting parameters\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "g6jOv1EmoKMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Final Script\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "xXhVQt7OoDEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_script(df_dealer, df_retail, dealer_date_columns, retail_date_columns):\n",
        "\n",
        "    print(\"Number of rows and columns in the dealer dataset\")\n",
        "    print(\"# of rows: {}\".format(df_dealer.shape[0]))\n",
        "    print(\"# of columns: {}\\n\".format(df_dealer.shape[1]))\n",
        "\n",
        "    print(\"----//----//----//----//----//----//----//----\")\n",
        "    print(\"Number of rows and columns in the retail dataset\")\n",
        "    print(\"# of rows: {}\".format(df_retail.shape[0]))\n",
        "    print(\"# of columns: {}\".format(df_retail.shape[1]))\n",
        "\n",
        "    # Fix date format\n",
        "    start_time = time.time()\n",
        "    print(\"\\nFixing the date for each dataset\")\n",
        "    fix_date_format(df_dealer, dealer_date_columns)\n",
        "    fix_date_format(df_retail, retail_date_columns)\n",
        "    end_time = time.time()\n",
        "    print(f\"Finished the date fixing functions in {round(end_time-start_time,2)} seconds \\n\")\n",
        "    print(\"----//----//----//----//----//----//----//----\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(\"Adjusting city names in the dealer dataset\")\n",
        "    # Clean and fix city names\n",
        "    df_dealer = clean_city_names(df_dealer)\n",
        "    end_time = time.time()\n",
        "    print(f\"Finished the city adjusting functions in  {round(end_time-start_time,2)} seconds \\n\")\n",
        "    print(\"----//----//----//----//----//----//----//----\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(\"General cleaning in both datasets\")\n",
        "    # Clean the dealer and retail datasets\n",
        "    df_dealer = clean_dealer_dataset(df_dealer)\n",
        "    df_retail = clean_retail_dataset(df_retail)\n",
        "    end_time = time.time()\n",
        "    print(f\"Finished the general cleaning in  {round(end_time-start_time,2)} seconds \\n\")\n",
        "    print(\"----//----//----//----//----//----//----//----\")\n",
        "\n",
        "    # Merge datasets\n",
        "    start_time = time.time()\n",
        "    print(\"Merging datasets\")\n",
        "    df_merged = merge_datasets(df_dealer, df_retail)\n",
        "    end_time = time.time()\n",
        "    print(f\"Finished the data merging in  {round(end_time-start_time,2)} seconds \\n\")\n",
        "\n",
        "    return df_merged"
      ],
      "metadata": {
        "id": "0baWj9uPoFb6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = final_script(df_dealer, df_retail, dealer_date_columns, retail_date_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NyoL2eMpeEF",
        "outputId": "926e4e3f-6170-497c-cc5e-33c452537dfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows and columns in the dealer dataset\n",
            "# of rows: 4153\n",
            "# of columns: 23\n",
            "\n",
            "----//----//----//----//----//----//----//----\n",
            "Number of rows and columns in the retail dataset\n",
            "# of rows: 134261\n",
            "# of columns: 21\n",
            "\n",
            "Fixing the date for each dataset\n",
            "Finished the date fixing functions in 18.19 seconds \n",
            "\n",
            "----//----//----//----//----//----//----//----\n",
            "Adjusting city names in the dealer dataset\n",
            "Finished the city adjusting functions in  0.01 seconds \n",
            "\n",
            "----//----//----//----//----//----//----//----\n",
            "General cleaning in both datasets\n",
            "Finished the general cleaning in  0.11 seconds \n",
            "\n",
            "----//----//----//----//----//----//----//----\n",
            "Merging datasets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-bd2614c9f61e>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dealer['CITY_DEALER'].fillna('no city found', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished the data merging in  0.18 seconds \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_merged_file = '/content/sample_data/NEW_MERGED.csv'\n",
        "df_merged.to_csv(new_merged_file, index=False)"
      ],
      "metadata": {
        "id": "okEPdWLApN3s"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}